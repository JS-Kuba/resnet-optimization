{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tUCJ0kT1J602"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO & tips:\n",
        "# - hp tuning - wg instrukcji\n",
        "# - zrobić kwantyzacje post training\n",
        "# - pomiary czasu inferencji (testu) na baseline, pruned i quantized\n",
        "# - pomiary wielkości modelu (pliku/wymaganej pamięci)\n",
        "# - ustawiać nazwę swojego GPU (przy każdym wandb init)\n",
        "# - można wyłączać logowanie\n",
        "# - prezentacja, dokumentacja\n",
        "# - uwaga bo pliki modeli się nadpisują"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ETAP DODATKOWY - Inicjalizacja logowania"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "GPU_1 = \"NVIDIA GeForce GTX 1060 6GB\"\n",
        "GPU_2 = \"NVIDIA GeForce RTX 3060 12GB\"\n",
        "\n",
        "PICKED_GPU = GPU_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WandbLogger:\n",
        "    def __init__(self, disable_logging) -> None:\n",
        "        self.disable_logging = disable_logging\n",
        "\n",
        "    def initialize(self, config, name, gpu):\n",
        "        if not self.disable_logging:\n",
        "            config[\"gpu\"] = gpu\n",
        "\n",
        "            wandb.init(\n",
        "                project=\"ososn-project\",\n",
        "                name=name,\n",
        "                config=config\n",
        "            )\n",
        "\n",
        "    def log_loss(self, train_loss, val_loss, step):\n",
        "        if not self.disable_logging:\n",
        "            wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss}, step=step)\n",
        "\n",
        "    def log_sparsity(self, sparsity, step):\n",
        "        if not self.disable_logging:\n",
        "            wandb.log({\"sparsity\": sparsity}, step=step)\n",
        "\n",
        "    def log_time(self, time):\n",
        "        if not self.disable_logging:\n",
        "            wandb.log({\"train_time\": round(time, 3)})\n",
        "\n",
        "    def log_accuracy(self, accuracy, tag, step):\n",
        "        if not self.disable_logging:\n",
        "            wandb.log({f\"{tag} accuracy\": accuracy}, step=step)\n",
        "\n",
        "    def log_f1_score(self, f1_score, tag, step):\n",
        "        if not self.disable_logging:\n",
        "            wandb.log({f\"{tag} f1_score\": f1_score}, step=step)\n",
        "\n",
        "    def log_recall(self, recall, tag, step):\n",
        "        if not self.disable_logging:\n",
        "            wandb.log({f\"{tag} recall\": recall}, step=step)\n",
        "\n",
        "    def log_precision(self, precision, tag, step):\n",
        "        if not self.disable_logging:\n",
        "            wandb.log({f\"{tag} precision\": precision}, step=step)\n",
        "    \n",
        "    def finish(self):\n",
        "        if not self.disable_logging:\n",
        "            wandb.finish()\n",
        "\n",
        "class Report:\n",
        "    @staticmethod\n",
        "    def report_results(y_true, y_pred, tag, wandb_logger, step=None):\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        wandb_logger.log_accuracy(acc, tag, step)\n",
        "\n",
        "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "        recall = recall_score(y_true, y_pred, average='weighted')\n",
        "        precision = precision_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "        if tag == \"test\":\n",
        "            wandb_logger.log_f1_score(f1, tag, step)\n",
        "            wandb_logger.log_recall(recall, tag, step)\n",
        "            wandb_logger.log_precision(precision, tag, step)\n",
        "        \n",
        "        return acc, f1, recall, precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Etap 2 - Wybór danych i modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: resnet18, Parameters: 11,227,812 (11.23M)\n",
            "\n",
            "Epoch 1/1\n",
            "Train Loss: 2.0291, Acc: 0.4532\n",
            "Epoch training time: 143.89 sec\n",
            "Peak memory usage (training): 2022.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 2.0424, Acc: 0.4624\n",
            "Training finished.\n",
            "\n",
            "Test Acc: 0.4610, F1: 0.4526, Recall: 0.4610, Precision: 0.5835\n",
            "Inference Time (total): 16.62 sec\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "hp_sanity = {\n",
        "    \"num_epochs\": 1,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"batch_size\": 64,\n",
        "    \"model_name\": \"resnet18\",\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# === TRANSFORMACJE ===\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "NUM_CLASSES = 100\n",
        "\n",
        "if not os.path.exists('./data/cifar-100-python'):\n",
        "    download = True\n",
        "else:\n",
        "    download = False\n",
        "\n",
        "train_set_full = torchvision.datasets.CIFAR100(root='./data', train=True, download=download, transform=transform_train)\n",
        "test_set_full = torchvision.datasets.CIFAR100(root='./data', train=False, download=download, transform=transform_test)\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_len = int(0.9 * len(train_set_full))\n",
        "val_len = len(train_set_full) - train_len\n",
        "train_subset, val_subset = random_split(train_set_full, [train_len, val_len], generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "train_subset.dataset.transform = transform_train\n",
        "val_subset.dataset.transform = transform_test\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=hp_sanity[\"batch_size\"], shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_subset, batch_size=hp_sanity[\"batch_size\"], shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_set_full, batch_size=hp_sanity[\"batch_size\"], shuffle=False)\n",
        "\n",
        "wandb_logger = WandbLogger(disable_logging=True)\n",
        "wandb_logger.initialize(\n",
        "    config=hp_sanity,\n",
        "    name=f\"{hp_sanity['model_name']}-baseline-bs{hp_sanity['batch_size']}\",\n",
        "    gpu=PICKED_GPU,\n",
        ")\n",
        "\n",
        "try:\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, NUM_CLASSES)\n",
        "    model = model.to(device)\n",
        "\n",
        "    model_size = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Model: {hp_sanity['model_name']}, Parameters: {model_size:,} ({model_size / 1e6:.2f}M)\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=hp_sanity[\"learning_rate\"])\n",
        "\n",
        "    def train_model(model, dataloader, optimizer, criterion, num_epochs):\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        best_acc = 0.0\n",
        "        torch.cuda.reset_peak_memory_stats(device)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            start_epoch = time.time()\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_time = time.time() - start_epoch\n",
        "            epoch_train_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_train_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "            mem_allocated = torch.cuda.max_memory_allocated(device) / (1024 ** 2)\n",
        "\n",
        "            print(f\"Train Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.4f}\")\n",
        "            print(f\"Epoch training time: {epoch_time:.2f} sec\")\n",
        "            print(f\"Peak memory usage (training): {mem_allocated:.2f} MB\")\n",
        "\n",
        "            wandb_logger.log_accuracy(epoch_train_acc, \"train\", epoch + 1)\n",
        "            wandb_logger.log_loss(epoch_train_loss, 0.0, epoch + 1)  # dummy val loss here\n",
        "            wandb_logger.log_time(epoch_time)\n",
        "\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_preds = []\n",
        "            val_labels = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    val_preds.extend(preds.cpu().numpy())\n",
        "                    val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "            val_acc, val_f1, val_recall, val_precision = Report.report_results(val_labels, val_preds, tag=\"val\", wandb_logger=wandb_logger, step=epoch + 1)\n",
        "\n",
        "            print(f\"Val Loss: {epoch_val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
        "            wandb_logger.log_loss(epoch_train_loss, epoch_val_loss, epoch + 1)\n",
        "\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print(\"Training finished.\")\n",
        "        model.load_state_dict(best_model_wts)\n",
        "        return model\n",
        "\n",
        "    def evaluate_model(model, dataloader, wandb_logger):\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "        test_acc, test_f1, test_recall, test_precision = Report.report_results(all_labels, all_preds, tag=\"test\", wandb_logger=wandb_logger)\n",
        "        print(f\"\\nTest Acc: {test_acc:.4f}, F1: {test_f1:.4f}, Recall: {test_recall:.4f}, Precision: {test_precision:.4f}\")\n",
        "        print(f\"Inference Time (total): {inference_time:.2f} sec\")\n",
        "\n",
        "    trained_model = train_model(model, train_loader, optimizer, criterion, hp_sanity[\"num_epochs\"])\n",
        "    evaluate_model(trained_model, test_loader, wandb_logger)\n",
        "\n",
        "finally:\n",
        "    wandb_logger.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ETAP TRZECI - Określenie zadania docelowego i przygotowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "hp_baseline = {\n",
        "        \"num_epochs\": 5,\n",
        "        \"learning_rate\": 1e-3,\n",
        "        # \"weight_decay\": 1e-4,\n",
        "        \"batch_size\": 64,\n",
        "        \"model_name\": \"resnet18\",\n",
        "        \"noise_level\": 0.05\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "B8uD0a9eiC39"
      },
      "outputs": [],
      "source": [
        "# === MAPOWANIE KLAS ===\n",
        "class_mapping = {\n",
        "    0: [4, 30, 55, 72, 95],\n",
        "    1: [1, 32, 67, 73, 91],\n",
        "    2: [54, 62, 70, 82, 92],\n",
        "    3: [9, 10, 16, 28, 61],\n",
        "    4: [0, 51, 53, 57, 83],\n",
        "    5: [22, 39, 40, 86, 87],\n",
        "    6: [5, 20, 25, 84, 94],\n",
        "    7: [6, 7, 14, 18, 24],\n",
        "    8: [3, 42, 43, 88, 97],\n",
        "    9: [12, 17, 37, 68, 76],\n",
        "    10: [23, 33, 49, 60, 71],\n",
        "    11: [15, 19, 21, 31, 38],\n",
        "    12: [34, 63, 64, 66, 75],\n",
        "    13: [26, 45, 77, 79, 99],\n",
        "    14: [2, 11, 35, 46, 98],\n",
        "    15: [27, 29, 44, 78, 93],\n",
        "    16: [36, 50, 65, 74, 80],\n",
        "    17: [47, 52, 56, 59, 96],\n",
        "    18: [8, 13, 48, 58, 90],\n",
        "    19: [41, 69, 81, 85, 89]\n",
        "}\n",
        "\n",
        "custom_class_names = [\n",
        "    'aquatic mammals', 'fish', 'flowers', 'food containers', 'fruit and vegetables',\n",
        "    'household electrical device', 'household furniture', 'insects', 'large carnivores',\n",
        "    'large man-made outdoor things', 'large natural outdoor scenes', 'large omnivores and herbivores',\n",
        "    'medium-sized mammals', 'non-insect invertebrates', 'people', 'reptiles',\n",
        "    'small mammals', 'trees', 'vehicles 1', 'vehicles 2'\n",
        "]\n",
        "\n",
        "label_remap = {orig: new for new, orig_list in class_mapping.items() for orig in orig_list}\n",
        "NUM_CLASSES = len(class_mapping)\n",
        "\n",
        "# === PRZYGOTOWANIE DANYCH ===\n",
        "if not os.path.exists('./data/cifar-100-python'):\n",
        "    download = True\n",
        "else:\n",
        "    download = False\n",
        "\n",
        "train_set_full = torchvision.datasets.CIFAR100(root='./data', train=True, download=download, transform=transform_train)\n",
        "test_set_full = torchvision.datasets.CIFAR100(root='./data', train=False, download=download, transform=transform_test)\n",
        "\n",
        "\n",
        "# === TRANSFORMACJE ===\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
        "                         std=[0.2673, 0.2564, 0.2761]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
        "                         std=[0.2673, 0.2564, 0.2761]),\n",
        "])\n",
        "\n",
        "\n",
        "def remap_dataset(dataset):\n",
        "    images, labels = [], []\n",
        "    for img, label in zip(dataset.data, dataset.targets):\n",
        "        if label in label_remap:\n",
        "            images.append(img)\n",
        "            labels.append(label_remap[label])\n",
        "    dataset.data = images\n",
        "    dataset.targets = labels\n",
        "    dataset.classes = custom_class_names\n",
        "    return dataset\n",
        "\n",
        "train_set = remap_dataset(train_set_full)\n",
        "test_set = remap_dataset(test_set_full)\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_len = int(0.9 * len(train_set))\n",
        "val_len = len(train_set) - train_len\n",
        "train_subset, val_subset = random_split(train_set, [train_len, val_len], generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "# Szumienie etykiet (10%)\n",
        "def add_label_noise(dataset, noise_level=0.1):\n",
        "    if isinstance(dataset, torch.utils.data.Subset):\n",
        "        for i in range(len(dataset)):\n",
        "            if random.random() < noise_level:\n",
        "                true_index = dataset.indices[i]\n",
        "                dataset.dataset.targets[true_index] = random.randint(0, NUM_CLASSES - 1)\n",
        "    else:\n",
        "        for i in range(len(dataset.targets)):\n",
        "            if random.random() < noise_level:\n",
        "                dataset.targets[i] = random.randint(0, NUM_CLASSES - 1)\n",
        "    return dataset\n",
        "\n",
        "train_subset.dataset.transform = transform_train\n",
        "val_subset.dataset.transform = transform_test\n",
        "\n",
        "train_set = add_label_noise(train_set, noise_level=hp_baseline[\"noise_level\"])\n",
        "\n",
        "# Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=hp_baseline[\"batch_size\"], shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_subset, batch_size=hp_baseline[\"batch_size\"], shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=hp_baseline[\"batch_size\"], shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ETAP 4 - Douczanie modelu odniesienia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\tomek\\Desktop\\projects\\OSiOwSN_projekt\\resnet-optimization\\wandb\\run-20250612_134459-lp58tvjj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zpd-project/ososn-project/runs/lp58tvjj' target=\"_blank\">resnet18-baseline-bs64-noise0.05</a></strong> to <a href='https://wandb.ai/zpd-project/ososn-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/zpd-project/ososn-project' target=\"_blank\">https://wandb.ai/zpd-project/ososn-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/zpd-project/ososn-project/runs/lp58tvjj' target=\"_blank\">https://wandb.ai/zpd-project/ososn-project/runs/lp58tvjj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: resnet18, Parameters: 11.19M\n",
            "Epoch 1/5\n",
            "Train loss: 1.5134, Train acc: 0.5583, Val loss: 1.2706, Val acc 0.6374\n",
            "Epoch 2/5\n",
            "Train loss: 1.0947, Train acc: 0.6953, Val loss: 1.2433, Val acc 0.6496\n",
            "Epoch 3/5\n",
            "Train loss: 0.8805, Train acc: 0.7612, Val loss: 1.1015, Val acc 0.7062\n",
            "Epoch 4/5\n",
            "Train loss: 0.6731, Train acc: 0.8203, Val loss: 1.1597, Val acc 0.7020\n",
            "Epoch 5/5\n",
            "Train loss: 0.4844, Train acc: 0.8685, Val loss: 1.3400, Val acc 0.6770\n",
            "Training complete in 13m 46s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.7216, Test f1: 0.7202, Test recall: 0.7216, Test precision 0.7493\n",
            "Inference time: 18.53s\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test accuracy</td><td>▁</td></tr><tr><td>test f1_score</td><td>▁</td></tr><tr><td>test precision</td><td>▁</td></tr><tr><td>test recall</td><td>▁</td></tr><tr><td>train accuracy</td><td>▁▄▆▇█</td></tr><tr><td>train_loss</td><td>█▅▄▂▁</td></tr><tr><td>train_time</td><td>▁</td></tr><tr><td>val accuracy</td><td>▁▂██▅</td></tr><tr><td>val_loss</td><td>▆▅▁▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test accuracy</td><td>0.7216</td></tr><tr><td>test f1_score</td><td>0.72023</td></tr><tr><td>test precision</td><td>0.74934</td></tr><tr><td>test recall</td><td>0.7216</td></tr><tr><td>train accuracy</td><td>0.86853</td></tr><tr><td>train_loss</td><td>0.48441</td></tr><tr><td>train_time</td><td>826.279</td></tr><tr><td>val accuracy</td><td>0.677</td></tr><tr><td>val_loss</td><td>1.34005</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-baseline-bs64-noise0.05</strong> at: <a href='https://wandb.ai/zpd-project/ososn-project/runs/lp58tvjj' target=\"_blank\">https://wandb.ai/zpd-project/ososn-project/runs/lp58tvjj</a><br> View project at: <a href='https://wandb.ai/zpd-project/ososn-project' target=\"_blank\">https://wandb.ai/zpd-project/ososn-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20250612_134459-lp58tvjj\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb_logger = WandbLogger(disable_logging=False)\n",
        "wandb_logger.initialize(\n",
        "    config=hp_baseline,\n",
        "    name=f\"{hp_baseline[\"model_name\"]}-baseline-bs{hp_baseline[\"batch_size\"]}-noise{hp_baseline[\"noise_level\"]}\",\n",
        "    gpu=PICKED_GPU,\n",
        ")\n",
        "\n",
        "try:\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, NUM_CLASSES)\n",
        "    model = model.to(device)\n",
        "    model_size = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Model: {hp_baseline[\"model_name\"]}, Parameters: {model_size / 1e6:.2f}M\")\n",
        "        \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=hp_baseline[\"learning_rate\"])\n",
        "\n",
        "    def train_model(model, dataloader, optimizer, criterion, num_epochs):\n",
        "        since = time.time()\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "            epoch_train_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "            wandb_logger.log_accuracy(epoch_train_acc, \"train\", epoch+1)\n",
        "\n",
        "            # === Walidacja ===\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_preds = []\n",
        "            val_labels = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    val_preds.extend(preds.cpu().numpy())\n",
        "                    val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "            wandb_logger.log_loss(epoch_train_loss, epoch_val_loss, epoch+1)\n",
        "            val_acc, val_f1, val_recall, val_precision = Report.report_results(val_labels, val_preds, tag=\"val\", wandb_logger=wandb_logger, step=epoch+1)\n",
        "\n",
        "            print(f\"Train loss: {epoch_train_loss:.4f}, Train acc: {epoch_train_acc:.4f}, Val loss: {epoch_val_loss:.4f}, Val acc {val_acc:.4f}\")\n",
        "\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), f\"models/best_model_{hp_baseline[\"model_name\"]}.pth\")\n",
        "\n",
        "        total_time = time.time() - since\n",
        "        wandb_logger.log_time(total_time)\n",
        "\n",
        "        print(f\"Training complete in {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
        "        model.load_state_dict(best_model_wts)\n",
        "        return model\n",
        "\n",
        "    # === EWALUACJA ===\n",
        "    def evaluate_model(model, dataloader, wandb_logger, device=\"cuda\"):\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        start = time.time()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        duration = time.time() - start\n",
        "\n",
        "        test_acc, test_f1, test_recall, test_precision = Report.report_results(all_labels, all_preds, tag=\"test\", wandb_logger=wandb_logger)\n",
        "        print(f\"Test acc: {test_acc:.4f}, Test f1: {test_f1:.4f}, Test recall: {test_recall:.4f}, Test precision {test_precision:.4f}\")\n",
        "        print(f\"Inference time: {duration:.2f}s\")\n",
        "\n",
        "\n",
        "    base_model = train_model(model, train_loader, optimizer, criterion, hp_baseline[\"num_epochs\"])\n",
        "    evaluate_model(base_model, test_loader, wandb_logger)\n",
        "    torch.save(base_model.state_dict(), f\"models/final_model_{hp_baseline[\"model_name\"]}.pth\")\n",
        "finally:\n",
        "    wandb_logger.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
            "Unsupported operator aten::add_ encountered 8 time(s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FLOPS: 1,818,564,096\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "import torch.nn as nn\n",
        "\n",
        "model.load_state_dict(torch.load(\"models/best_model_resnet18_base.pth\", map_location=device))\n",
        "best_base_model = model.to(device)\n",
        "best_base_model.eval()\n",
        "\n",
        "input_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "flops = FlopCountAnalysis(best_base_model, input_tensor)\n",
        "print(f\"FLOPS: {flops.total():,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42.71092224121094"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_model_size_mb(model):\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.nelement() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.nelement() * buffer.element_size()\n",
        "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "    return size_all_mb\n",
        "\n",
        "get_model_size_mb(best_base_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ETAP 5 - Optymalizacja modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "def apply_pruning(model, current_sparsity):\n",
        "    # Przerzedzanie konwolucyjnych wag, procent current_sparsity np. 0.1 (10%)\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            prune.l1_unstructured(module, name='weight', amount=current_sparsity)\n",
        "\n",
        "def remove_pruning(model):\n",
        "    # Usuwa maski, zachowuje sparsity na stałe\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            if prune.is_pruned(module):\n",
        "                prune.remove(module, 'weight')\n",
        "\n",
        "def count_nonzero_params(model):\n",
        "    nonzero = total = 0\n",
        "    for p in model.parameters():\n",
        "        total += p.numel()\n",
        "        nonzero += p.nonzero().size(0)\n",
        "    return nonzero, total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\tomek\\Desktop\\projects\\OSiOwSN_projekt\\resnet-optimization\\wandb\\run-20250612_153916-euppx80t</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zpd-project/ososn-project/runs/euppx80t' target=\"_blank\">resnet18-pruned-bs64-noise0.05-sparsity0.75</a></strong> to <a href='https://wandb.ai/zpd-project/ososn-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/zpd-project/ososn-project' target=\"_blank\">https://wandb.ai/zpd-project/ososn-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/zpd-project/ososn-project/runs/euppx80t' target=\"_blank\">https://wandb.ai/zpd-project/ososn-project/runs/euppx80t</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: resnet18, Parameters: 11.19M\n",
            "\n",
            "Epoch 1/5\n",
            "Applied pruning: sparsity = 0.00\n",
            "Train loss: 1.5324, Train acc: 0.5510, Val loss: 1.2708, Val acc 0.6354\n",
            "Nonzero params: 11186772 / 11186772 (100.00%)\n",
            "Saved new best model.\n",
            "\n",
            "Epoch 2/5\n",
            "Applied pruning: sparsity = 0.32\n",
            "Train loss: 1.0173, Train acc: 0.7201, Val loss: 1.0790, Val acc 0.7124\n",
            "Nonzero params: 11186772 / 11186772 (100.00%)\n",
            "Saved new best model.\n",
            "\n",
            "Epoch 3/5\n",
            "Applied pruning: sparsity = 0.51\n",
            "Train loss: 0.7260, Train acc: 0.8103, Val loss: 1.0635, Val acc 0.7242\n",
            "Nonzero params: 11180988 / 11186772 (99.95%)\n",
            "Saved new best model.\n",
            "\n",
            "Epoch 4/5\n",
            "Applied pruning: sparsity = 0.65\n",
            "Train loss: 0.4609, Train acc: 0.8772, Val loss: 1.2726, Val acc 0.7056\n",
            "Nonzero params: 11180988 / 11186772 (99.95%)\n",
            "\n",
            "Epoch 5/5\n",
            "Applied pruning: sparsity = 0.75\n",
            "Train loss: 0.2591, Train acc: 0.9273, Val loss: 1.4005, Val acc 0.7194\n",
            "Nonzero params: 11180988 / 11186772 (99.95%)\n",
            "Training complete in 14m 51s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.7532, Test f1: 0.7500, Test recall: 0.7532, Test precision 0.7590\n",
            "Inference time: 21.26s\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>sparsity</td><td>▁▄▆▇█</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>test f1_score</td><td>▁</td></tr><tr><td>test precision</td><td>▁</td></tr><tr><td>test recall</td><td>▁</td></tr><tr><td>train accuracy</td><td>▁▄▆▇█</td></tr><tr><td>train_loss</td><td>█▅▄▂▁</td></tr><tr><td>train_time</td><td>▁</td></tr><tr><td>val accuracy</td><td>▁▇█▇█</td></tr><tr><td>val_loss</td><td>▅▁▁▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>sparsity</td><td>0.75</td></tr><tr><td>test accuracy</td><td>0.7532</td></tr><tr><td>test f1_score</td><td>0.74996</td></tr><tr><td>test precision</td><td>0.75901</td></tr><tr><td>test recall</td><td>0.7532</td></tr><tr><td>train accuracy</td><td>0.92727</td></tr><tr><td>train_loss</td><td>0.25914</td></tr><tr><td>train_time</td><td>891.154</td></tr><tr><td>val accuracy</td><td>0.7194</td></tr><tr><td>val_loss</td><td>1.40046</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18-pruned-bs64-noise0.05-sparsity0.75</strong> at: <a href='https://wandb.ai/zpd-project/ososn-project/runs/euppx80t' target=\"_blank\">https://wandb.ai/zpd-project/ososn-project/runs/euppx80t</a><br> View project at: <a href='https://wandb.ai/zpd-project/ososn-project' target=\"_blank\">https://wandb.ai/zpd-project/ososn-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20250612_153916-euppx80t\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "hp_pruning = {\n",
        "    \"num_epochs\": 5,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    # \"weight_decay\": 1e-4,\n",
        "    \"batch_size\": 64,\n",
        "    \"model_name\": \"resnet18\",\n",
        "    \"noise_level\": 0.05,\n",
        "    \"max_sparsity\": 0.75,\n",
        "    \"schedule\": \"log\"\n",
        "}\n",
        "wandb_logger = WandbLogger(disable_logging=False)\n",
        "wandb_logger.initialize(\n",
        "    config=hp_pruning,\n",
        "    name=f\"{hp_pruning['model_name']}-pruned-bs{hp_pruning['batch_size']}-noise{hp_pruning['noise_level']}-sparsity{hp_pruning['max_sparsity']}\",\n",
        "    gpu=PICKED_GPU\n",
        ")\n",
        "\n",
        "try:\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, NUM_CLASSES)\n",
        "    model = model.to(device)\n",
        "    model_size = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Model: {hp_pruning['model_name']}, Parameters: {model_size / 1e6:.2f}M\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=hp_pruning[\"learning_rate\"])\n",
        "\n",
        "    def train_model_with_pruning(model, train_loader, val_loader, optimizer, criterion, num_epochs, max_sparsity):\n",
        "        since = time.time()\n",
        "        best_acc = 0.0\n",
        "        best_model_wts = None\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Pruning schedule\n",
        "            # current_sparsity = max_sparsity * (epoch / (num_epochs - 1))\n",
        "            # logarithmic schedule\n",
        "            current_sparsity = max_sparsity * math.log(epoch + 1) / math.log(num_epochs)\n",
        "\n",
        "            wandb_logger.log_sparsity(current_sparsity, epoch+1)\n",
        "            # Remove old masks (if any)\n",
        "            for name, module in model.named_modules():\n",
        "                if isinstance(module, torch.nn.Conv2d):\n",
        "                    try:\n",
        "                        prune.remove(module, 'weight')\n",
        "                    except ValueError:\n",
        "                        pass\n",
        "\n",
        "            # Apply new sparsity\n",
        "            apply_pruning(model, current_sparsity)\n",
        "            print(f\"Applied pruning: sparsity = {current_sparsity:.2f}\")\n",
        "\n",
        "            # === Train ===\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "            epoch_train_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "            wandb_logger.log_accuracy(epoch_train_acc, \"train\", epoch + 1)\n",
        "\n",
        "            # === Val ===\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_preds = []\n",
        "            val_labels = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    val_preds.extend(preds.cpu().numpy())\n",
        "                    val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "            wandb_logger.log_loss(epoch_train_loss, epoch_val_loss, epoch + 1)\n",
        "\n",
        "            val_acc, val_f1, val_recall, val_precision = Report.report_results(\n",
        "                val_labels, val_preds, tag=\"val\", wandb_logger=wandb_logger, step=epoch + 1\n",
        "            )\n",
        "\n",
        "            print(f\"Train loss: {epoch_train_loss:.4f}, Train acc: {epoch_train_acc:.4f}, Val loss: {epoch_val_loss:.4f}, Val acc {val_acc:.4f}\")\n",
        "\n",
        "            nonzero, total = count_nonzero_params(model)\n",
        "            print(f\"Nonzero params: {nonzero} / {total} ({100 * nonzero / total:.2f}%)\")\n",
        "\n",
        "            # Save best model\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                remove_pruning(model)\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(best_model_wts, f\"models/best_model_pruned_{hp_pruning['model_name']}.pth\")\n",
        "                print(\"Saved new best model.\")\n",
        "\n",
        "        total_time = time.time() - since\n",
        "        print(f\"Training complete in {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
        "        wandb_logger.log_time(total_time)\n",
        "\n",
        "        if best_model_wts:\n",
        "            remove_pruning(model)\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        return model\n",
        "\n",
        "    # === Ewaluacja ===\n",
        "    def evaluate_model(model, dataloader, wandb_logger):\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        start = time.time()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        duration = time.time() - start\n",
        "\n",
        "        test_acc, test_f1, test_recall, test_precision = Report.report_results(\n",
        "            all_labels, all_preds, tag=\"test\", wandb_logger=wandb_logger\n",
        "        )\n",
        "        print(f\"Test acc: {test_acc:.4f}, Test f1: {test_f1:.4f}, Test recall: {test_recall:.4f}, Test precision {test_precision:.4f}\")\n",
        "        print(f\"Inference time: {duration:.2f}s\")\n",
        "\n",
        "    # === Trening + Ewaluacja ===\n",
        "    model = train_model_with_pruning(\n",
        "        model, train_loader, val_loader, optimizer, criterion,\n",
        "        num_epochs=hp_pruning[\"num_epochs\"],\n",
        "        max_sparsity=hp_pruning[\"max_sparsity\"]\n",
        "    )\n",
        "    evaluate_model(model, test_loader, wandb_logger)\n",
        "    torch.save(model.state_dict(), f\"models/final_model_pruned_{hp_pruning['model_name']}.pth\")\n",
        "\n",
        "finally:\n",
        "    wandb_logger.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rozmiar modelu przed pruningiem (gzip): 40611.58 KB\n",
            "Rozmiar modelu po pruningiem (gzip): 23839.02 KB\n",
            "Stopień kompresji: 1.70x\n",
            "Procent kompresji: 41.30%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "def save_model_to_file(model, path):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def get_gzipped_model_size(original_path):\n",
        "    # Kompresuje .pth do .gz i zwraca rozmiar w bajtach\n",
        "    gzipped_path = original_path + \".gz\"\n",
        "    with open(original_path, 'rb') as f_in:\n",
        "        with gzip.open(gzipped_path, 'wb') as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "    size = os.path.getsize(gzipped_path)\n",
        "    return size\n",
        "\n",
        "base_path=\"models/best_model_resnet18_base.pth\"\n",
        "pruned_path =\"models/best_model_pruned_resnet18.pth\"\n",
        "# save_model_to_file(model, base_path)\n",
        "save_model_to_file(model, pruned_path)\n",
        "\n",
        "# Kompresja\n",
        "base_size = get_gzipped_model_size(base_path)\n",
        "pruned_size = get_gzipped_model_size(pruned_path)\n",
        "\n",
        "print(f\"Rozmiar modelu przed pruningiem (gzip): {base_size / 1024:.2f} KB\")\n",
        "print(f\"Rozmiar modelu po pruningu (gzip): {pruned_size / 1024:.2f} KB\")\n",
        "print(f\"Stopień kompresji: {base_size / pruned_size:.2f}x\")\n",
        "print(f\"Procent kompresji: {(1 - pruned_size / base_size) * 100:.2f}%\")\n",
        "\n",
        "# linear 0.5\n",
        "# Rozmiar modelu przed pruningiem (gzip): 40660.24 KB\n",
        "# Rozmiar modelu po pruningiem (gzip): 32393.43 KB\n",
        "# Stopień kompresji: 1.26x\n",
        "# Procent kompresji: 20.33%\n",
        "\n",
        "\n",
        "# log 0.75\n",
        "# Rozmiar modelu przed pruningiem (gzip): 40660.24 KB\n",
        "# Rozmiar modelu po pruningiem (gzip): 17150.66 KB\n",
        "# Stopień kompresji: 2.37x\n",
        "# Procent kompresji: 57.82%\n",
        "\n",
        "# log 0.75 + weight_decay\n",
        "# Rozmiar modelu przed pruningiem (gzip): 40660.24 KB\n",
        "# Rozmiar modelu po pruningiem (gzip): 25955.67 KB\n",
        "# Stopień kompresji: 1.57x\n",
        "# Procent kompresji: 36.16%\n",
        "\n",
        "# log 0.9\n",
        "# Rozmiar modelu przed pruningiem (gzip): 40660.24 KB\n",
        "# Rozmiar modelu po pruningiem (gzip): 19072.71 KB\n",
        "# Stopień kompresji: 2.13x\n",
        "# Procent kompresji: 53.09%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
            "Unsupported operator aten::add_ encountered 8 time(s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FLOPS: 1,818,564,096\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "import torch.nn as nn\n",
        "\n",
        "model.load_state_dict(torch.load(\"models/best_model_pruned_resnet18.pth\", map_location=device))\n",
        "best_base_model_pruned = model.to(device)\n",
        "best_base_model_pruned.eval()\n",
        "\n",
        "input_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "flops = FlopCountAnalysis(best_base_model_pruned, input_tensor)\n",
        "print(f\"FLOPS: {flops.total():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ETAP 6 - Dodakowe optymalizacje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pruned model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== ORIGINAL MODEL EVALUATION ===\n",
            "Original (Pruned) - Accuracy: 76.24%, Inference time: 19.37s\n",
            "\n",
            "=== POST-TRAINING QUANTIZATION (FX) ===\n",
            "Applying Post-Training Quantization (FX Graph Mode)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\ao\\quantization\\quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
            "  prepared = prepare(\n",
            "c:\\Users\\tomek\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:244: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibrating model...\n",
            "\n",
            "=== QUANTIZED MODEL EVALUATION ===\n",
            "Quantized (PTQ) - Accuracy: 76.33%, Inference time: 25.32s\n",
            "\n",
            "============================================================\n",
            "QUANTIZATION RESULTS COMPARISON\n",
            "============================================================\n",
            "Metric               Original        Quantized       Change         \n",
            "-----------------------------------------------------------------\n",
            "Accuracy (%)         76.24           76.33           +0.09          \n",
            "Model Size (MB)      42.76           10.80           -74.8          %\n",
            "Inference Time (s)   19.37           25.32           +30.7          %\n",
            "Compression Ratio    1.0x            4.0x            -              \n",
            "\n",
            "Quantized model saved to: models/quantized_model_resnet18.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import time\n",
        "import copy\n",
        "from torch.ao.quantization import get_default_qconfig, prepare, convert\n",
        "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
        "\n",
        "NUM_CLASSES = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_pruned_model(model_path, num_classes=20):\n",
        "    model = torchvision.models.resnet18(pretrained=False)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    \n",
        "    state_dict = torch.load(model_path, map_location='cpu')\n",
        "    model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, dataloader, device, model_name=\"Model\"):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    inference_time = time.time() - start_time\n",
        "    accuracy = 100 * correct / total\n",
        "    \n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.2f}%, Inference time: {inference_time:.2f}s\")\n",
        "    return accuracy, inference_time\n",
        "\n",
        "def get_model_size(model):\n",
        "    import io\n",
        "    buffer = io.BytesIO()\n",
        "    torch.save(model, buffer)\n",
        "    size_bytes = buffer.tell()\n",
        "    buffer.close()\n",
        "    \n",
        "    return size_bytes / 1024**2\n",
        "\n",
        "def create_data_loader_cpu(original_loader):\n",
        "    cpu_data = []\n",
        "    cpu_labels = []\n",
        "    \n",
        "    for i, (inputs, labels) in enumerate(original_loader):\n",
        "        if i >= 20:  # limit calibration data\n",
        "            break\n",
        "        cpu_data.append(inputs)\n",
        "        cpu_labels.append(labels)\n",
        "    \n",
        "    class CPUDataLoader:\n",
        "        def __init__(self, data, labels):\n",
        "            self.data = data\n",
        "            self.labels = labels\n",
        "        \n",
        "        def __iter__(self):\n",
        "            for d, l in zip(self.data, self.labels):\n",
        "                yield d, l\n",
        "    \n",
        "    return CPUDataLoader(cpu_data, cpu_labels)\n",
        "\n",
        "def post_training_quantization_fx(model, calibration_loader):\n",
        "    print(\"Applying Post-Training Quantization (FX Graph Mode)...\")\n",
        "    model.cpu()\n",
        "    model.eval()\n",
        "    qconfig_dict = {\"\": get_default_qconfig('x86')}\n",
        "    model_prepared = prepare_fx(model, qconfig_dict, example_inputs=(torch.randn(1, 3, 32, 32),))\n",
        "    print(\"Calibrating model...\")\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in calibration_loader:\n",
        "            model_prepared(inputs)\n",
        "    model_quantized = convert_fx(model_prepared)\n",
        "    \n",
        "    return model_quantized\n",
        "\n",
        "def post_training_quantization_eager(model, calibration_loader):\n",
        "    print(\"Applying Post-Training Quantization (Eager Mode)...\")\n",
        "    model.cpu()\n",
        "    model.eval()\n",
        "    model_fused = torch.ao.quantization.fuse_modules(model, [['conv1', 'bn1', 'relu']])\n",
        "    model_fused.qconfig = get_default_qconfig('x86')\n",
        "    model_prepared = prepare(model_fused, inplace=False)\n",
        "    print(\"Calibrating model...\")\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in calibration_loader:\n",
        "            model_prepared(inputs)\n",
        "    model_quantized = convert(model_prepared, inplace=False)\n",
        "    \n",
        "    return model_quantized\n",
        "\n",
        "def run_quantization_experiment(pruned_model_path, train_loader, test_loader):\n",
        "    print(\"Loading pruned model...\")\n",
        "    original_model = load_pruned_model(pruned_model_path, NUM_CLASSES)\n",
        "    original_model = original_model.to(device)\n",
        "    print(\"\\n=== ORIGINAL MODEL EVALUATION ===\")\n",
        "    orig_acc, orig_time = evaluate_model(original_model, test_loader, device, \"Original (Pruned)\")\n",
        "    orig_size = get_model_size(original_model)\n",
        "    calibration_loader = create_data_loader_cpu(train_loader)\n",
        "    try:\n",
        "        print(\"\\n=== POST-TRAINING QUANTIZATION (FX) ===\")\n",
        "        quantized_model = post_training_quantization_fx(original_model, calibration_loader)\n",
        "    except Exception as e:\n",
        "        print(f\"FX quantization failed: {e}\")\n",
        "        print(\"\\n=== POST-TRAINING QUANTIZATION (Eager) ===\")\n",
        "        quantized_model = post_training_quantization_eager(original_model, calibration_loader)\n",
        "    cpu_test_loader = create_data_loader_cpu(test_loader)\n",
        "    print(\"\\n=== QUANTIZED MODEL EVALUATION ===\")\n",
        "    quant_acc, quant_time = evaluate_model(quantized_model, cpu_test_loader, torch.device('cpu'), \"Quantized (PTQ)\")\n",
        "    quant_size = get_model_size(quantized_model)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"QUANTIZATION RESULTS COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"{'Metric':<20} {'Original':<15} {'Quantized':<15} {'Change':<15}\")\n",
        "    print(\"-\" * 65)\n",
        "    print(f\"{'Accuracy (%)':<20} {orig_acc:<15.2f} {quant_acc:<15.2f} {quant_acc-orig_acc:<+15.2f}\")\n",
        "    print(f\"{'Model Size (MB)':<20} {orig_size:<15.2f} {quant_size:<15.2f} {((quant_size/orig_size-1)*100):<+15.1f}%\")\n",
        "    print(f\"{'Inference Time (s)':<20} {orig_time:<15.2f} {quant_time:<15.2f} {((quant_time/orig_time-1)*100):<+15.1f}%\")\n",
        "    print(f\"{'Compression Ratio':<20} {'1.0x':<15} {f'{orig_size/quant_size:.1f}x':<15} {'-':<15}\")\n",
        "    \n",
        "    torch.save(quantized_model.state_dict(), f\"models/quantized_model_resnet18.pth\")\n",
        "    print(f\"\\nQuantized model saved to: models/quantized_model_resnet18.pth\")\n",
        "    \n",
        "    return original_model, quantized_model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pruned_model_path = f\"models/best_model_pruned_resnet18.pth\"\n",
        "    \n",
        "    original_model, quantized_model = run_quantization_experiment(\n",
        "        pruned_model_path, \n",
        "        train_loader,\n",
        "        test_loader\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rozmiar modelu po kwantyzacji na int8 i kompresji (gzip): 7193.64 KB\n"
          ]
        }
      ],
      "source": [
        "quant_compressed = get_gzipped_model_size(\"models/quantized_model_resnet18.pth\")\n",
        "print(f\"Rozmiar modelu po kwantyzacji na int8 i kompresji (gzip): {quant_compressed / 1024:.2f} KB\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
